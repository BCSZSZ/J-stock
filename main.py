"""
J-Stock-Analyzer - ç»Ÿä¸€CLIå…¥å£
æä¾›3ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼šæ•°æ®æŠ“å–ã€ç­–ç•¥ä¿¡å·ç”Ÿæˆã€å›æµ‹åˆ†æ
"""
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime


def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path('config.json')
    if not config_path.exists():
        print("âŒ é”™è¯¯: config.json ä¸å­˜åœ¨")
        sys.exit(1)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_monitor_list(config: dict) -> list:
    """ä»monitor_list.jsonæˆ–monitor_list.txtåŠ è½½è‚¡ç¥¨ä»£ç åˆ—è¡¨"""
    # Try JSON first (new format)
    json_file = Path("data/monitor_list.json")
    if json_file.exists():
        import json
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return [stock['code'] for stock in data['tickers']]
    
    # Fallback to TXT (old format)
    list_file = Path(config['data']['monitor_list_file'])
    if not list_file.exists():
        print(f"âŒ é”™è¯¯: ç›‘è§†åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨ {list_file}")
        sys.exit(1)
    
    tickers = []
    with open(list_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
            if line and not line.startswith('#'):
                tickers.append(line)
    
    return tickers


def cmd_fetch(args):
    """æ•°æ®æŠ“å–å‘½ä»¤"""
    from src.data_fetch_manager import main as fetch_main, load_monitor_list as fetch_load_list
    
    config = load_config()
    
    if args.all:
        print("ğŸ“¥ æŠ“å–ç›‘è§†åˆ—è¡¨ä¸­çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®...")
        fetch_main()
    elif args.tickers:
        print(f"ğŸ“¥ æŠ“å–æŒ‡å®šè‚¡ç¥¨æ•°æ®: {', '.join(args.tickers)}")
        # ä¸´æ—¶è¦†ç›–monitor list
        import os
        from src.data.pipeline import StockETLPipeline
        from src.data.benchmark_manager import update_benchmarks
        from src.client.jquants_client import JQuantsV2Client
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv('JQUANTS_API_KEY')
        
        if not api_key:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° JQUANTS_API_KEY")
            return
        
        # æ›´æ–°TOPIXåŸºå‡†
        client = JQuantsV2Client(api_key)
        benchmark_result = update_benchmarks(client)
        
        if benchmark_result['success']:
            print(f"âœ… TOPIXå·²æ›´æ–°: {benchmark_result['topix_records']} æ¡è®°å½•")
        
        # æŠ“å–æŒ‡å®šè‚¡ç¥¨
        pipeline = StockETLPipeline(api_key)
        summary = pipeline.run_batch(args.tickers, fetch_aux_data=True)
        
        print(f"\nâœ… æ•°æ®æŠ“å–å®Œæˆ: {summary['successful']}/{summary['total']} åªè‚¡ç¥¨æˆåŠŸ")
    else:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®š --all æˆ– --tickers")


def cmd_signal(args):
    """ç­–ç•¥ä¿¡å·ç”Ÿæˆå‘½ä»¤"""
    from src.signal_generator import generate_trading_signal
    
    config = load_config()
    
    # ä½¿ç”¨æŒ‡å®šæ—¥æœŸæˆ–ä»Šå¤©
    target_date = args.date if args.date else datetime.now().strftime('%Y-%m-%d')
    
    entry_strategy = args.entry or config['default_strategies']['entry']
    exit_strategy = args.exit or config['default_strategies']['exit']
    
    print(f"\nğŸ¯ ç”Ÿæˆäº¤æ˜“ä¿¡å·")
    print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
    print(f"   æ—¥æœŸ: {target_date}")
    print(f"   å…¥åœºç­–ç•¥: {entry_strategy}")
    print(f"   å‡ºåœºç­–ç•¥: {exit_strategy}")
    print("="*60)
    
    signal = generate_trading_signal(
        ticker=args.ticker,
        date=target_date,
        entry_strategy=entry_strategy,
        exit_strategy=exit_strategy
    )
    
    if signal:
        print(f"\nâœ… ä¿¡å·ç”ŸæˆæˆåŠŸ")
        print(f"   åŠ¨ä½œ: {signal['action']}")
        print(f"   ç½®ä¿¡åº¦: {signal.get('confidence', 'N/A')}")
        if signal.get('reason'):
            print(f"   åŸå› : {signal['reason']}")
    else:
        print(f"\nâš ï¸ æ— äº¤æ˜“ä¿¡å·")


def cmd_backtest(args):
    """å•è‚¡ç¥¨å›æµ‹å‘½ä»¤"""
    config = load_config()
    from src.utils.strategy_loader import (
        get_all_strategy_combinations,
        get_strategy_combinations_from_lists,
        load_entry_strategy,
        load_exit_strategy,
        ENTRY_STRATEGIES,
        EXIT_STRATEGIES
    )
    from src.backtest.engine import backtest_strategy
    from src.backtest.lot_size_manager import LotSizeManager
    from src.data.stock_data_manager import StockDataManager
    from src.utils.output_logger import create_logger
    import pandas as pd
    
    # åŠ è½½lot sizesé…ç½®
    if 'lot_sizes' in config:
        LotSizeManager.load_from_config(config['lot_sizes'])
    
    # å¯åŠ¨æ—¥å¿—è¾“å‡º
    logger = create_logger('backtest', ticker=args.ticker)
    with logger:
        # ç¡®å®šè¦æµ‹è¯•çš„ç­–ç•¥ç»„åˆ
        if args.all_strategies:
            # æ¨¡å¼1ï¼šå…¨éƒ¨ç­–ç•¥ç»„åˆ
            strategy_combinations = get_all_strategy_combinations()
            print(f"\nğŸ“Š å•è‚¡ç¥¨å›æµ‹ - æ‰€æœ‰ç­–ç•¥ç»„åˆ")
            print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
            print(f"   ç­–ç•¥ç»„åˆæ•°: {len(strategy_combinations)}")
        elif args.entry or args.exit:
            # æ¨¡å¼2ï¼šæŒ‡å®šç­–ç•¥ï¼ˆæ”¯æŒåˆ—è¡¨ï¼‰
            # å¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼Œå¦‚æœæŒ‡å®šåˆ™è½¬ä¸ºåˆ—è¡¨
            if args.entry:
                entry_names = args.entry if isinstance(args.entry, list) else [args.entry]
            else:
                entry_names = [config['default_strategies']['entry']]
            
            if args.exit:
                exit_names = args.exit if isinstance(args.exit, list) else [args.exit]
            else:
                exit_names = [config['default_strategies']['exit']]
            
            strategy_combinations = get_strategy_combinations_from_lists(entry_names, exit_names)
            
            if len(strategy_combinations) > 1:
                print(f"\nğŸ“Š å•è‚¡ç¥¨å›æµ‹ - å¤šç­–ç•¥ç»„åˆ")
                print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
                print(f"   å…¥åœºç­–ç•¥: {', '.join(entry_names)}")
                print(f"   å‡ºåœºç­–ç•¥: {', '.join(exit_names)}")
                print(f"   ç­–ç•¥ç»„åˆæ•°: {len(strategy_combinations)}")
            else:
                print(f"\nğŸ“Š å•è‚¡ç¥¨å›æµ‹")
                print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
                print(f"   å…¥åœºç­–ç•¥: {entry_names[0]}")
                print(f"   å‡ºåœºç­–ç•¥: {exit_names[0]}")
        else:
            # æ¨¡å¼3ï¼šä½¿ç”¨é»˜è®¤ç­–ç•¥
            entry_name = config['default_strategies']['entry']
            exit_name = config['default_strategies']['exit']
            strategy_combinations = [(entry_name, exit_name)]
            print(f"\nğŸ“Š å•è‚¡ç¥¨å›æµ‹")
            print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
            print(f"   å…¥åœºç­–ç•¥: {entry_name}")
            print(f"   å‡ºåœºç­–ç•¥: {exit_name}")
    
        capital = args.capital or config['backtest']['starting_capital_jpy']
        
        # å¤„ç†æ—¶é—´èŒƒå›´ï¼šä¼˜å…ˆçº§ --years > --start/--end > configé»˜è®¤å€¼
        if args.years:
            # ä½¿ç”¨æœ€è¿‘xå¹´çš„æ•°æ®
            end_date = args.end or config['backtest']['end_date']
            from datetime import datetime
            from dateutil.relativedelta import relativedelta
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            start_dt = end_dt - relativedelta(years=args.years)
            start_date = start_dt.strftime('%Y-%m-%d')
            print(f"   æ—¶é—´èŒƒå›´: æœ€è¿‘{args.years}å¹´ ({start_date} â†’ {end_date})")
        else:
            start_date = args.start or config['backtest']['start_date']
            end_date = args.end or config['backtest']['end_date']
            print(f"   æ—¶é—´èŒƒå›´: {start_date} â†’ {end_date}")
        
        print(f"   èµ·å§‹èµ„é‡‘: Â¥{capital:,}")
        print("="*60)
        
        # åŠ è½½æ•°æ®ï¼ˆåªè¯»æ¨¡å¼ï¼‰
        data_manager = StockDataManager()
        stock_data = data_manager.load_stock_features(args.ticker)
        
        if stock_data.empty:
            print(f"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ {args.ticker} çš„æ•°æ®æ–‡ä»¶")
            print(f"   è¯·å…ˆè¿è¡Œ: python main.py fetch --tickers {args.ticker}")
            return
        
        # æ‰§è¡Œå›æµ‹
        results = []
        for i, (entry_name, exit_name) in enumerate(strategy_combinations, 1):
            if len(strategy_combinations) > 1:
                print(f"\n[{i}/{len(strategy_combinations)}] {entry_name} Ã— {exit_name}")
            
            # åˆ›å»ºç­–ç•¥å®ä¾‹
            entry_strategy = load_entry_strategy(entry_name)
            exit_strategy = load_exit_strategy(exit_name)
            
            # æ‰§è¡Œå›æµ‹
            result = backtest_strategy(
                ticker=args.ticker,
                scorer=entry_strategy,
                exiter=exit_strategy,
                start_date=start_date,
                end_date=end_date,
                starting_capital_jpy=capital
            )
            
            results.append({
                'entry': entry_name,
                'exit': exit_name,
                'result': result
            })
            
            # æ˜¾ç¤ºç»“æœ
            if len(strategy_combinations) == 1:
                print(f"\nğŸ“ˆ å›æµ‹ç»“æœ")
                print(f"   æœ€ç»ˆèµ„é‡‘: Â¥{result.final_capital_jpy:,.0f}")
                print(f"   æ€»æ”¶ç›Šç‡: {result.total_return_pct:.2f}%")
                print(f"   äº¤æ˜“æ¬¡æ•°: {result.num_trades}")
                print(f"   èƒœç‡: {result.win_rate_pct:.1f}%")
                print(f"   æœ€å¤§å›æ’¤: {result.max_drawdown_pct:.2f}%")
                if result.sharpe_ratio:
                    print(f"   å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
                print(f"\n   ä¹°å…¥æŒæœ‰æ”¶ç›Š: {result.buy_hold_return_pct:.2f}%")
                print(f"   æ‹©æ—¶Alpha: {result.timing_alpha:.2f}%")
                if result.benchmark_return_pct:
                    print(f"   TOPIXæ”¶ç›Š: {result.benchmark_return_pct:.2f}%")
                    print(f"   é€‰è‚¡Alpha: {result.stock_selection_alpha:.2f}%")
            else:
                # ç®€è¦æ˜¾ç¤º
                print(f"   æ”¶ç›Šç‡: {result.total_return_pct:6.2f}% | å¤æ™®: {result.sharpe_ratio:5.2f} | å›æ’¤: {result.max_drawdown_pct:5.2f}% | äº¤æ˜“: {result.num_trades:3d}æ¬¡")
        
        # å¦‚æœæ˜¯å¤šç­–ç•¥ï¼Œæ˜¾ç¤ºæ’å
        if len(results) > 1:
            print(f"\n\n{'='*80}")
            print("ç­–ç•¥æ’å (æŒ‰æ”¶ç›Šç‡)")
            print(f"{'='*80}")
            sorted_results = sorted(results, key=lambda x: x['result'].total_return_pct, reverse=True)
            
            print(f"{'æ’å':<4} {'å…¥åœºç­–ç•¥':<25} {'å‡ºåœºç­–ç•¥':<25} {'æ”¶ç›Šç‡':>10} {'å¤æ™®':>8} {'èƒœç‡':>8}")
            print("-" * 80)
            for i, item in enumerate(sorted_results, 1):
                r = item['result']
                print(f"{i:<4} {item['entry']:<25} {item['exit']:<25} {r.total_return_pct:>9.2f}% {r.sharpe_ratio:>7.2f} {r.win_rate_pct:>7.1f}%")


def cmd_backtest_old(args):
    """åŸå§‹å•è‚¡ç¥¨å›æµ‹å‘½ä»¤ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰"""
    config = load_config()
    
    entry_strategy = args.entry or config['default_strategies']['entry']
    exit_strategy = args.exit or config['default_strategies']['exit']
    start_date = args.start or config['backtest']['start_date']
    end_date = args.end or config['backtest']['end_date']
    capital = args.capital or config['backtest']['starting_capital_jpy']
    
    print(f"\nğŸ“Š å•è‚¡ç¥¨å›æµ‹")
    print(f"   è‚¡ç¥¨ä»£ç : {args.ticker}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} â†’ {end_date}")
    print(f"   èµ·å§‹èµ„é‡‘: Â¥{capital:,}")
    print(f"   å…¥åœºç­–ç•¥: {entry_strategy}")
    print(f"   å‡ºåœºç­–ç•¥: {exit_strategy}")
    print("="*60)
    
    from src.backtest.engine import BacktestEngine, backtest_strategy
    from pathlib import Path
    import pandas as pd
    
    # ç›´æ¥ä»parquetæ–‡ä»¶åŠ è½½æ•°æ®
    features_path = Path('data/features') / f"{args.ticker}_features.parquet"
    
    if not features_path.exists():
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ {args.ticker} çš„æ•°æ®æ–‡ä»¶")
        print(f"   è¯·å…ˆè¿è¡Œ: python main.py fetch --tickers {args.ticker}")
        return
    
    stock_data = pd.read_parquet(features_path)
    stock_data = pd.read_parquet(features_path)
    
    if stock_data.empty:
        print(f"âŒ é”™è¯¯: è‚¡ç¥¨ {args.ticker} çš„æ•°æ®ä¸ºç©º")
        return
    
    # æ ‡å‡†åŒ–æ—¥æœŸåˆ—
    if 'Date' in stock_data.columns:
        stock_data = stock_data.rename(columns={'Date': 'date'})
    stock_data['date'] = pd.to_datetime(stock_data['date']).dt.strftime('%Y-%m-%d')
    
    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
    stock_data = stock_data[
        (stock_data['date'] >= start_date) & 
        (stock_data['date'] <= end_date)
    ]
    
    if stock_data.empty:
        print(f"âŒ é”™è¯¯: æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ— æ•°æ®")
        return
    
    # æ‰§è¡Œå›æµ‹
    result = backtest_strategy(
        ticker=args.ticker,
        stock_data=stock_data,
        entry_strategy_name=entry_strategy,
        exit_strategy_name=exit_strategy,
        starting_capital=capital
    )
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“ˆ å›æµ‹ç»“æœ")
    print(f"   æœ€ç»ˆèµ„é‡‘: Â¥{result.final_capital_jpy:,.0f}")
    print(f"   æ€»æ”¶ç›Šç‡: {result.total_return_pct:.2f}%")
    print(f"   äº¤æ˜“æ¬¡æ•°: {result.num_trades}")
    print(f"   èƒœç‡: {result.win_rate_pct:.1f}%")
    print(f"   æœ€å¤§å›æ’¤: {result.max_drawdown_pct:.2f}%")
    if result.sharpe_ratio:
        print(f"   å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
    
    print(f"\n   ä¹°å…¥æŒæœ‰æ”¶ç›Š: {result.buy_hold_return_pct:.2f}%")
    print(f"   æ‹©æ—¶Alpha: {result.timing_alpha:.2f}%")
    
    if result.benchmark_return_pct:
        print(f"   TOPIXæ”¶ç›Š: {result.benchmark_return_pct:.2f}%")
        print(f"   é€‰è‚¡Alpha: {result.stock_selection_alpha:.2f}%")


def cmd_portfolio(args):
    """ç»„åˆæŠ•èµ„å›æµ‹å‘½ä»¤"""
    config = load_config()
    from src.utils.strategy_loader import (
        get_all_strategy_combinations,
        get_strategy_combinations_from_lists,
        load_entry_strategy,
        load_exit_strategy
    )
    from src.backtest.portfolio_engine import PortfolioBacktestEngine
    from src.backtest.lot_size_manager import LotSizeManager
    from src.data.stock_data_manager import StockDataManager
    from src.utils.output_logger import create_logger
    import pandas as pd
    
    # åŠ è½½lot sizesé…ç½®
    if 'lot_sizes' in config:
        LotSizeManager.load_from_config(config['lot_sizes'])
    
    # å¯åŠ¨æ—¥å¿—è¾“å‡º
    logger = create_logger('portfolio')
    with logger:
        # ç¡®å®šè¦å›æµ‹çš„è‚¡ç¥¨åˆ—è¡¨
        if args.all:
            tickers = load_monitor_list(config)
            print(f"ğŸ“Š ç»„åˆæŠ•èµ„å›æµ‹ - ç›‘è§†åˆ—è¡¨æ‰€æœ‰è‚¡ç¥¨ ({len(tickers)}åª)")
        elif args.tickers:
            tickers = args.tickers
            print(f"ğŸ“Š ç»„åˆæŠ•èµ„å›æµ‹ - æŒ‡å®šè‚¡ç¥¨ ({len(tickers)}åª)")
        else:
            print("âŒ é”™è¯¯: è¯·æŒ‡å®š --all æˆ– --tickers")
            return
        
        # ç¡®å®šè¦æµ‹è¯•çš„ç­–ç•¥ç»„åˆ
        if args.all_strategies:
            # æ¨¡å¼1ï¼šå…¨éƒ¨ç­–ç•¥ç»„åˆ
            strategy_combinations = get_all_strategy_combinations()
            print(f"   ç­–ç•¥ç»„åˆæ•°: {len(strategy_combinations)}")
        elif args.entry or args.exit:
            # æ¨¡å¼2ï¼šæŒ‡å®šç­–ç•¥ï¼ˆæ”¯æŒåˆ—è¡¨ï¼‰
            if args.entry:
                entry_names = args.entry if isinstance(args.entry, list) else [args.entry]
            else:
                entry_names = [config['default_strategies']['entry']]
            
            if args.exit:
                exit_names = args.exit if isinstance(args.exit, list) else [args.exit]
            else:
                exit_names = [config['default_strategies']['exit']]
            
            strategy_combinations = get_strategy_combinations_from_lists(entry_names, exit_names)
            
            if len(strategy_combinations) > 1:
                print(f"   å…¥åœºç­–ç•¥: {', '.join(entry_names)}")
                print(f"   å‡ºåœºç­–ç•¥: {', '.join(exit_names)}")
                print(f"   ç­–ç•¥ç»„åˆæ•°: {len(strategy_combinations)}")
            else:
                print(f"   å…¥åœºç­–ç•¥: {entry_names[0]}")
                print(f"   å‡ºåœºç­–ç•¥: {exit_names[0]}")
        else:
            # æ¨¡å¼3ï¼šä½¿ç”¨é»˜è®¤ç­–ç•¥
            entry_name = config['default_strategies']['entry']
            exit_name = config['default_strategies']['exit']
            strategy_combinations = [(entry_name, exit_name)]
            print(f"   å…¥åœºç­–ç•¥: {entry_name}")
            print(f"   å‡ºåœºç­–ç•¥: {exit_name}")
        
        capital = args.capital or config['backtest']['starting_capital_jpy']
        
        # å¤„ç†æ—¶é—´èŒƒå›´ï¼šä¼˜å…ˆçº§ --years > --start/--end > configé»˜è®¤å€¼
        if args.years:
            # ä½¿ç”¨æœ€è¿‘xå¹´çš„æ•°æ®
            end_date = args.end or config['backtest']['end_date']
            from datetime import datetime
            from dateutil.relativedelta import relativedelta
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            start_dt = end_dt - relativedelta(years=args.years)
            start_date = start_dt.strftime('%Y-%m-%d')
            print(f"   æ—¶é—´èŒƒå›´: æœ€è¿‘{args.years}å¹´ ({start_date} â†’ {end_date})")
        else:
            start_date = args.start or config['backtest']['start_date']
            end_date = args.end or config['backtest']['end_date']
            print(f"   æ—¶é—´èŒƒå›´: {start_date} â†’ {end_date}")
        
        print(f"   è‚¡ç¥¨ä»£ç : {', '.join(tickers[:5])}{'...' if len(tickers) > 5 else ''}")
        print(f"   èµ·å§‹èµ„é‡‘: Â¥{capital:,}")
        print(f"   æœ€å¤§æŒä»“: {config['portfolio']['max_positions']}åª")
        print("="*60)
        
        # åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆåªè¯»æ¨¡å¼ï¼‰
        data_manager = StockDataManager()
        all_data = {}
        
        for ticker in tickers:
            stock_data = data_manager.load_stock_features(ticker)
            
            if stock_data.empty:
                print(f"âš ï¸ è·³è¿‡ {ticker}: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            # æ ‡å‡†åŒ–æ—¥æœŸåˆ—
            if 'Date' in stock_data.columns:
                stock_data = stock_data.rename(columns={'Date': 'date'})
            stock_data['date'] = pd.to_datetime(stock_data['date']).dt.strftime('%Y-%m-%d')
            
            # è¿‡æ»¤æ—¥æœŸ
            stock_data = stock_data[
                (stock_data['date'] >= start_date) & 
                (stock_data['date'] <= end_date)
            ]
            
            if not stock_data.empty:
                all_data[ticker] = stock_data
        
        print(f"\nâœ… æˆåŠŸåŠ è½½ {len(all_data)}/{len(tickers)} åªè‚¡ç¥¨æ•°æ®")
        
        if len(all_data) == 0:
            print("âŒ é”™è¯¯: æ— å¯ç”¨æ•°æ®")
            return
        
        # æ‰§è¡Œç»„åˆå›æµ‹
        results = []
        for i, (entry_name, exit_name) in enumerate(strategy_combinations, 1):
            if len(strategy_combinations) > 1:
                print(f"\n[{i}/{len(strategy_combinations)}] {entry_name} Ã— {exit_name}")
            
            # åˆ›å»ºç­–ç•¥å®ä¾‹
            entry_strategy = load_entry_strategy(entry_name)
            exit_strategy = load_exit_strategy(exit_name)
            
            # æ‰§è¡Œç»„åˆå›æµ‹
            engine = PortfolioBacktestEngine(
                starting_capital=capital,
                max_positions=config['portfolio']['max_positions']
            )
            
            result = engine.backtest_portfolio_strategy(
                tickers=tickers,
                entry_strategy=entry_strategy,
                exit_strategy=exit_strategy,
                start_date=start_date,
                end_date=end_date
            )
            
            results.append({
                'entry': entry_name,
                'exit': exit_name,
                'result': result
            })
            
            # æ˜¾ç¤ºç»“æœ
            if len(strategy_combinations) == 1:
                print(f"\nğŸ“ˆ ç»„åˆå›æµ‹ç»“æœ")
                print(f"   æœ€ç»ˆèµ„é‡‘: Â¥{result.final_capital_jpy:,.0f}")
                print(f"   æ€»æ”¶ç›Šç‡: {result.total_return_pct:.2f}%")
                print(f"   äº¤æ˜“æ¬¡æ•°: {result.num_trades}")
                print(f"   èƒœç‡: {result.win_rate_pct:.1f}%")
                print(f"   æœ€å¤§å›æ’¤: {result.max_drawdown_pct:.2f}%")
                if result.sharpe_ratio:
                    print(f"   å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
                if result.benchmark_return_pct:
                    print(f"\n   TOPIXæ”¶ç›Š: {result.benchmark_return_pct:.2f}%")
                    print(f"   è¶…é¢æ”¶ç›Š: {result.total_return_pct - result.benchmark_return_pct:.2f}%")
            else:
                # ç®€è¦æ˜¾ç¤º
                print(f"   æ”¶ç›Šç‡: {result.total_return_pct:6.2f}% | å¤æ™®: {result.sharpe_ratio:5.2f} | å›æ’¤: {result.max_drawdown_pct:5.2f}% | äº¤æ˜“: {result.num_trades:3d}æ¬¡")
        
        # å¦‚æœæ˜¯å¤šç­–ç•¥ï¼Œæ˜¾ç¤ºæ’å
        if len(results) > 1:
            print(f"\n\n{'='*100}")
            print("ç­–ç•¥æ’å (æŒ‰æ”¶ç›Šç‡)")
            print(f"{'='*100}")
            sorted_results = sorted(results, key=lambda x: x['result'].total_return_pct, reverse=True)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰benchmarkæ•°æ®
            has_benchmark = any(r['result'].benchmark_return_pct is not None for r in sorted_results)
            
            if has_benchmark:
                print(f"{'æ’å':<4} {'å…¥åœºç­–ç•¥':<22} {'å‡ºåœºç­–ç•¥':<22} {'æ”¶ç›Šç‡':>10} {'å¤æ™®':>8} {'èƒœç‡':>8} {'TOPIX%':>9} {'è¶…é¢%':>9}")
                print("-" * 100)
                for i, item in enumerate(sorted_results, 1):
                    r = item['result']
                    topix_str = f"{r.benchmark_return_pct:>8.2f}%" if r.benchmark_return_pct is not None else "    N/A  "
                    alpha_str = f"{r.alpha:>8.2f}%" if r.alpha is not None else "    N/A  "
                    print(f"{i:<4} {item['entry']:<22} {item['exit']:<22} {r.total_return_pct:>9.2f}% {r.sharpe_ratio:>7.2f} {r.win_rate_pct:>7.1f}% {topix_str} {alpha_str}")
            else:
                print(f"{'æ’å':<4} {'å…¥åœºç­–ç•¥':<25} {'å‡ºåœºç­–ç•¥':<25} {'æ”¶ç›Šç‡':>10} {'å¤æ™®':>8} {'èƒœç‡':>8}")
                print("-" * 100)
                for i, item in enumerate(sorted_results, 1):
                    r = item['result']
                    print(f"{i:<4} {item['entry']:<25} {item['exit']:<25} {r.total_return_pct:>9.2f}% {r.sharpe_ratio:>7.2f} {r.win_rate_pct:>7.1f}%")


def cmd_portfolio_old(args):
    """åŸå§‹ç»„åˆæŠ•èµ„å›æµ‹å‘½ä»¤ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰"""
    config = load_config()
    
    # ç¡®å®šè¦å›æµ‹çš„è‚¡ç¥¨åˆ—è¡¨
    if args.all:
        tickers = load_monitor_list(config)
        print(f"ğŸ“Š ç»„åˆæŠ•èµ„å›æµ‹ - ç›‘è§†åˆ—è¡¨æ‰€æœ‰è‚¡ç¥¨ ({len(tickers)}åª)")
    elif args.tickers:
        tickers = args.tickers
        print(f"ğŸ“Š ç»„åˆæŠ•èµ„å›æµ‹ - æŒ‡å®šè‚¡ç¥¨ ({len(tickers)}åª)")
    else:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®š --all æˆ– --tickers")
        return
    
    entry_strategy = args.entry or config['default_strategies']['entry']
    exit_strategy = args.exit or config['default_strategies']['exit']
    start_date = args.start or config['backtest']['start_date']
    end_date = args.end or config['backtest']['end_date']
    capital = args.capital or config['backtest']['starting_capital_jpy']
    
    print(f"   è‚¡ç¥¨ä»£ç : {', '.join(tickers[:5])}{'...' if len(tickers) > 5 else ''}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} â†’ {end_date}")
    print(f"   èµ·å§‹èµ„é‡‘: Â¥{capital:,}")
    print(f"   æœ€å¤§æŒä»“: {config['portfolio']['max_positions']}åª")
    print(f"   å…¥åœºç­–ç•¥: {entry_strategy}")
    print(f"   å‡ºåœºç­–ç•¥: {exit_strategy}")
    print("="*60)
    
    from src.backtest.portfolio_engine import PortfolioBacktestEngine
    from src.data.stock_data_manager import StockDataManager
    import pandas as pd
    
    # åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆåªè¯»æ¨¡å¼ï¼‰
    data_manager = StockDataManager()  # ä¸éœ€è¦API key
    all_data = {}
    
    for ticker in tickers:
        stock_data = data_manager.load_stock_features(ticker)
        
        if stock_data.empty:
            print(f"âš ï¸ è·³è¿‡ {ticker}: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        # æ ‡å‡†åŒ–æ—¥æœŸåˆ—
        if 'Date' in stock_data.columns:
            stock_data = stock_data.rename(columns={'Date': 'date'})
        stock_data['date'] = pd.to_datetime(stock_data['date']).dt.strftime('%Y-%m-%d')
        
        # è¿‡æ»¤æ—¥æœŸ
        stock_data = stock_data[
            (stock_data['date'] >= start_date) & 
            (stock_data['date'] <= end_date)
        ]
        
        if not stock_data.empty:
            all_data[ticker] = stock_data
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(all_data)}/{len(tickers)} åªè‚¡ç¥¨æ•°æ®")
    
    if len(all_data) == 0:
        print("âŒ é”™è¯¯: æ— å¯ç”¨æ•°æ®")
        return
    
    # æ‰§è¡Œç»„åˆå›æµ‹
    engine = PortfolioBacktestEngine(
        starting_capital=capital,
        max_positions=config['portfolio']['max_positions'],
        lot_sizes=config['lot_sizes']
    )
    
    result = engine.run(
        all_stock_data=all_data,
        entry_strategy_name=entry_strategy,
        exit_strategy_name=exit_strategy
    )
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“ˆ ç»„åˆå›æµ‹ç»“æœ")
    print(f"   æœ€ç»ˆèµ„é‡‘: Â¥{result.final_capital_jpy:,.0f}")
    print(f"   æ€»æ”¶ç›Šç‡: {result.total_return_pct:.2f}%")
    print(f"   äº¤æ˜“æ¬¡æ•°: {result.num_trades}")
    print(f"   èƒœç‡: {result.win_rate_pct:.1f}%")
    print(f"   æœ€å¤§å›æ’¤: {result.max_drawdown_pct:.2f}%")
    if result.sharpe_ratio:
        print(f"   å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.2f}")
    
    if result.benchmark_return_pct:
        print(f"\n   TOPIXæ”¶ç›Š: {result.benchmark_return_pct:.2f}%")
        print(f"   è¶…é¢æ”¶ç›Š: {result.total_return_pct - result.benchmark_return_pct:.2f}%")


def cmd_universe(args):
    """è‚¡ç¥¨å®‡å®™é€‰è‚¡ï¼ˆæ­£å¼ç‰ˆå‘½ä»¤ï¼Œæ”¯æŒåˆ†æ‰¹ä¸æ–­ç‚¹ç»­ä¼ ï¼‰"""
    import os
    import json
    from dotenv import load_dotenv
    from src.data.stock_data_manager import StockDataManager
    from src.universe.stock_selector import UniverseSelector
    import pandas as pd
    from pathlib import Path
    from datetime import datetime

    # ========== ç¯å¢ƒä¸ç»„ä»¶ ==========
    load_dotenv()
    api_key = os.getenv('JQUANTS_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° JQUANTS_API_KEY")
        return

    print("\n" + "="*80)
    print("J-Stock Universe Selector - CLI (Batch + Resume)")
    if args.no_fetch:
        print("âš¡ NO-FETCHæ¨¡å¼: è·³è¿‡æ•°æ®æŠ“å–ï¼Œä½¿ç”¨ç°æœ‰æœ¬åœ°æ•°æ®")
    print("="*80 + "\n")
    manager = StockDataManager(api_key=api_key)
    selector = UniverseSelector(manager)

    # ========== åŠ è½½CSVå®‡å®™ï¼ˆä¸åšè¿‡æ»¤ï¼Œä¿ç•™ETFç­‰ï¼‰ ==========
    csv_path = Path(args.csv_file) if args.csv_file else Path('data/jpx_final_list.csv')
    if not csv_path.exists():
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°CSVæ–‡ä»¶ {csv_path}")
        return
    df = pd.read_csv(csv_path, encoding='utf-8')
    if 'Code' not in df.columns:
        print("âŒ é”™è¯¯: CSVç¼ºå°‘Codeåˆ—")
        return
    full_codes = df['Code'].astype(str).str.strip().tolist()
    if args.limit:
        full_codes = full_codes[:args.limit]
        print(f"ğŸ§ª é™åˆ¶æ¨¡å¼: ä»…å¤„ç†å‰ {args.limit} æ”¯è‚¡ç¥¨")

    # ========== Checkpoint IO ==========
    checkpoints_dir = Path('data/universe/checkpoints')
    checkpoints_dir.mkdir(parents=True, exist_ok=True)

    run_id = datetime.now().strftime('%Y%m%d_%H%M%S')
    checkpoint_path = Path(args.checkpoint) if args.checkpoint else checkpoints_dir / f'universe_run_{run_id}.json'

    def load_checkpoint(path: Path) -> dict:
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def save_checkpoint(state: dict) -> None:
        state['updated_at'] = datetime.now().isoformat()
        with open(checkpoint_path, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)

    # Initialize or resume
    processed_codes = set()
    failed_codes = set()
    last_index = 0
    batch_size = args.batch_size or 100

    consolidated_scores_path = Path('data/universe') / f'scores_all_{run_id}.parquet'

    if args.resume:
        state = load_checkpoint(checkpoint_path)
        if state:
            print(f"ğŸ” æ–­ç‚¹ç»­ä¼ : {checkpoint_path}")
            run_id = state.get('run_id', run_id)
            processed_codes = set(state.get('processed_codes', []))
            failed_codes = set(state.get('failed_codes', []))
            last_index = int(state.get('last_index', 0))
            consolidated_scores_path = Path(state.get('scores_path', consolidated_scores_path))
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„checkpointï¼ŒæŒ‰æ–°ä»»åŠ¡å¯åŠ¨")

    # Persist initial state
    save_checkpoint({
        'run_id': run_id,
        'csv_file': str(csv_path),
        'top_n': args.top_n,
        'batch_size': batch_size,
        'processed_codes': list(processed_codes),
        'failed_codes': list(failed_codes),
        'last_index': last_index,
        'scores_path': str(consolidated_scores_path),
        'created_at': datetime.now().isoformat()
    })

    print(f"ğŸš€ å¼€å§‹é€‰è‚¡ (Top {args.top_n})ï¼Œè‚¡ç¥¨æ•°: {len(full_codes)}ï¼Œæ‰¹å¤§å°: {batch_size}")

    # ========== Batch Loop ==========
    total = len(full_codes)
    start_idx = last_index
    while start_idx < total:
        end_idx = min(start_idx + batch_size, total)
        batch_codes = full_codes[start_idx:end_idx]

        # Skip codes already processed
        batch_codes = [c for c in batch_codes if c not in processed_codes]
        if not batch_codes:
            start_idx = end_idx
            continue

        print(f"\n[Batch {start_idx}-{end_idx}] å¤„ç† {len(batch_codes)} æ”¯è‚¡ç¥¨")
        try:
            df_top, df_scored = selector.run_selection(
                top_n=args.top_n,
                test_mode=False,
                test_limit=10,
                ticker_list=batch_codes,
                apply_filters=False,
                return_full=True,
                no_fetch=args.no_fetch
            )
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
            # æ ‡è®°æ•´æ‰¹å¤±è´¥çš„codesä¸ºå¤±è´¥ï¼ˆä¿ç•™ç»§ç»­èƒ½åŠ›ï¼‰
            for c in batch_codes:
                failed_codes.add(c)
            # æ›´æ–°checkpointå¹¶ç»§ç»­ä¸‹æ‰¹
            save_checkpoint({
                'run_id': run_id,
                'csv_file': str(csv_path),
                'top_n': args.top_n,
                'batch_size': batch_size,
                'processed_codes': list(processed_codes),
                'failed_codes': list(failed_codes),
                'last_index': end_idx,
                'scores_path': str(consolidated_scores_path),
                'created_at': datetime.now().isoformat()
            })
            start_idx = end_idx
            continue

        # Append consolidated scores
        try:
            if consolidated_scores_path.exists():
                # Append by concatenation
                existing = pd.read_parquet(consolidated_scores_path)
                combined = pd.concat([existing, df_scored], ignore_index=True)
                # Deduplicate by Code + DataDate
                subset_cols = [c for c in ['Code', 'DataDate'] if c in combined.columns]
                if subset_cols:
                    combined = combined.drop_duplicates(subset=subset_cols, keep='last')
                combined.to_parquet(consolidated_scores_path, index=False)
            else:
                df_scored.to_parquet(consolidated_scores_path, index=False)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¿½åŠ åˆå¹¶åˆ†æ•°: {e}")

        # Update processed set
        for c in batch_codes:
            processed_codes.add(c)

        # Update checkpoint
        save_checkpoint({
            'run_id': run_id,
            'csv_file': str(csv_path),
            'top_n': args.top_n,
            'batch_size': batch_size,
            'processed_codes': list(processed_codes),
            'failed_codes': list(failed_codes),
            'last_index': end_idx,
            'scores_path': str(consolidated_scores_path),
            'created_at': datetime.now().isoformat()
        })

        start_idx = end_idx

    # ========== Finalize ==========
    if consolidated_scores_path.exists():
        all_scores = pd.read_parquet(consolidated_scores_path)
        
        # ========== GLOBAL NORMALIZATION (5 dimensions) ==========
        print(f"\nğŸ“Š å…¨å±€å½’ä¸€åŒ– ({len(all_scores)} æ”¯è‚¡ç¥¨)")
        
        # Percentile ranking across all stocks
        all_scores['Rank_Vol'] = all_scores['ATR_Ratio'].rank(pct=True, ascending=True)
        all_scores['Rank_Liq'] = all_scores['MedianTurnover'].rank(pct=True, ascending=True)
        all_scores['Rank_Trend'] = all_scores['TrendStrength'].rank(pct=True, ascending=True)
        all_scores['Rank_Momentum'] = all_scores['Momentum_20d'].rank(pct=True, ascending=True)
        all_scores['Rank_VolSurge'] = all_scores['Volume_Surge'].rank(pct=True, ascending=True)
        
        # Weighted scoring (5 dimensions)
        WEIGHT_VOL = 0.25
        WEIGHT_LIQ = 0.25
        WEIGHT_TREND = 0.20
        WEIGHT_MOMENTUM = 0.20
        WEIGHT_VOLSURGE = 0.10
        
        all_scores['TotalScore'] = (
            WEIGHT_VOL * all_scores['Rank_Vol'] +
            WEIGHT_LIQ * all_scores['Rank_Liq'] +
            WEIGHT_TREND * all_scores['Rank_Trend'] +
            WEIGHT_MOMENTUM * all_scores['Rank_Momentum'] +
            WEIGHT_VOLSURGE * all_scores['Rank_VolSurge']
        )
        
        print(f"   æƒé‡åˆ†é…: Vol={WEIGHT_VOL}, Liq={WEIGHT_LIQ}, Trend={WEIGHT_TREND}, Momentum={WEIGHT_MOMENTUM}, VolSurge={WEIGHT_VOLSURGE}")
        print(f"   åˆ†æ•°èŒƒå›´: {all_scores['TotalScore'].min():.3f} - {all_scores['TotalScore'].max():.3f}")
        
        # Compute global top-N
        df_top_final = all_scores.nlargest(args.top_n, 'TotalScore').copy()
        df_top_final['Rank'] = range(1, len(df_top_final) + 1)

        # Summary print
        selector.print_summary(df_top_final, n=min(10, len(df_top_final)))

        # Save outputs
        json_path, csv_path = selector.save_selection_results(df_top_final, format='both')
        txt_path = selector.save_scores_txt(all_scores, df_top_final, top_n=args.top_n)

        print(f"\nâœ… å…¨é‡é€‰è‚¡å®Œæˆ")
        if json_path:
            print(f"ğŸ“„ JSON: {json_path}")
        if csv_path:
            print(f"ğŸ“Š CSV:  {csv_path}")
        if txt_path:
            print(f"ğŸ§¾ TXT:  {txt_path}")

    else:
        print("âš ï¸ æœªç”Ÿæˆåˆå¹¶åˆ†æ•°æ–‡ä»¶ï¼Œæ— æ³•è¾“å‡ºæœ€ç»ˆç»“æœ")

    def cmd_evaluate(args):
        """ç­–ç•¥ç»¼åˆè¯„ä»·å‘½ä»¤"""
        import json
        from src.evaluation import (
            StrategyEvaluator,
            create_annual_periods,
            create_monthly_periods,
            create_quarterly_periods
        )
    
        print("\n" + "="*80)
        print("ğŸ”¬ ç­–ç•¥ç»¼åˆè¯„ä»·ç³»ç»Ÿ")
        print("="*80 + "\n")
    
        # æ„é€ æ—¶é—´æ®µåˆ—è¡¨
        periods = []
    
        if args.mode == 'annual':
            # æ•´å¹´è¯„ä¼°
            if not args.years:
                print("âŒ é”™è¯¯: annualæ¨¡å¼éœ€è¦æŒ‡å®š--yearså‚æ•°")
                return
            periods = create_annual_periods(args.years)
            print(f"ğŸ“… è¯„ä¼°æ¨¡å¼: æ•´å¹´")
            print(f"   å¹´ä»½: {', '.join(map(str, args.years))}")
        
        elif args.mode == 'quarterly':
            # å­£åº¦è¯„ä¼°
            if not args.years:
                print("âŒ é”™è¯¯: quarterlyæ¨¡å¼éœ€è¦æŒ‡å®š--yearså‚æ•°")
                return
            periods = create_quarterly_periods(args.years)
            print(f"ğŸ“… è¯„ä¼°æ¨¡å¼: å­£åº¦")
            print(f"   å¹´ä»½: {', '.join(map(str, args.years))}")
        
        elif args.mode == 'monthly':
            # æœˆåº¦è¯„ä¼°
            if not args.years:
                print("âŒ é”™è¯¯: monthlyæ¨¡å¼éœ€è¦æŒ‡å®š--yearså‚æ•°")
                return
        
            months = args.months if args.months else list(range(1, 13))
            for year in args.years:
                periods.extend(create_monthly_periods(year, months))
        
            print(f"ğŸ“… è¯„ä¼°æ¨¡å¼: æœˆåº¦")
            print(f"   å¹´ä»½: {', '.join(map(str, args.years))}")
            print(f"   æœˆä»½: {', '.join(map(str, months))}")
        
        elif args.mode == 'custom':
            # è‡ªå®šä¹‰æ—¶é—´æ®µ
            if not args.custom_periods:
                print("âŒ é”™è¯¯: customæ¨¡å¼éœ€è¦æŒ‡å®š--custom-periodså‚æ•°")
                print('   æ ¼å¼: [["æ ‡ç­¾","å¼€å§‹æ—¥æœŸ","ç»“æŸæ—¥æœŸ"], ...]')
                print('   ç¤ºä¾‹: [["2021-Q1","2021-01-01","2021-03-31"], ["2021-Q2","2021-04-01","2021-06-30"]]')
                return
        
            try:
                periods = json.loads(args.custom_periods)
                print(f"ğŸ“… è¯„ä¼°æ¨¡å¼: è‡ªå®šä¹‰")
                print(f"   æ—¶é—´æ®µæ•°: {len(periods)}")
            except json.JSONDecodeError as e:
                print(f"âŒ é”™è¯¯: custom_periods JSONè§£æå¤±è´¥: {e}")
                return
    
        if not periods:
            print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´æ®µ")
            return
    
        print(f"\nğŸ“Š æ—¶é—´æ®µåˆ—è¡¨:")
        for label, start, end in periods[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"   {label}: {start} ~ {end}")
        if len(periods) > 5:
            print(f"   ... å…± {len(periods)} ä¸ªæ—¶é—´æ®µ")
    
        # åˆ›å»ºè¯„ä»·å™¨
        evaluator = StrategyEvaluator(
            data_root='data',
            output_dir=args.output_dir
        )
    
        # è¿è¡Œè¯„ä¼°
        print(f"\nğŸš€ å¼€å§‹ç­–ç•¥è¯„ä¼°...")
        df_results = evaluator.run_evaluation(
            periods=periods,
            entry_strategies=args.entry_strategies,
            exit_strategies=args.exit_strategies
        )
    
        if df_results.empty:
            print("âŒ è¯„ä¼°å¤±è´¥: æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœ")
            return
    
        # ä¿å­˜ç»“æœ
        print(f"\nğŸ’¾ ä¿å­˜ç»“æœ...")
        files = evaluator.save_results(prefix='strategy_evaluation')
    
        print(f"\n{'='*80}")
        print(f"âœ… ç­–ç•¥è¯„ä»·å®Œæˆï¼")
        print(f"{'='*80}")
        print(f"ğŸ“„ åŸå§‹ç»“æœ: {files['raw']}")
        print(f"ğŸ“Š å¸‚åœºç¯å¢ƒåˆ†æ: {files['regime']}")
        print(f"ğŸ“ ç»¼åˆæŠ¥å‘Š: {files['report']}")
        print(f"{'='*80}\n")

def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='J-Stock-Analyzer - æ—¥æœ¬è‚¡ç¥¨é‡åŒ–åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æ•°æ®æŠ“å–
  python main.py fetch --all                    # æŠ“å–ç›‘è§†åˆ—è¡¨æ‰€æœ‰è‚¡ç¥¨
  python main.py fetch --tickers 7974 8035      # æŠ“å–æŒ‡å®šè‚¡ç¥¨
  
  # ç”Ÿæˆäº¤æ˜“ä¿¡å·
  python main.py signal 7974                    # ç”Ÿæˆä»Šæ—¥ä¿¡å·
  python main.py signal 7974 --date 2026-01-10  # æŒ‡å®šæ—¥æœŸ
  
  # å•è‚¡ç¥¨å›æµ‹
  python main.py backtest 7974                  # ä½¿ç”¨é»˜è®¤å‚æ•°
  python main.py backtest 7974 --entry EnhancedScorerStrategy --exit LayeredExitStrategy
  
  # ç»„åˆæŠ•èµ„å›æµ‹
  python main.py portfolio --all                # å›æµ‹ç›‘è§†åˆ—è¡¨æ‰€æœ‰è‚¡ç¥¨
  python main.py portfolio --tickers 7974 8035 6501
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ========== æ•°æ®æŠ“å–å‘½ä»¤ ==========
    fetch_parser = subparsers.add_parser('fetch', help='æŠ“å–è‚¡ç¥¨æ•°æ®')
    fetch_group = fetch_parser.add_mutually_exclusive_group(required=True)
    fetch_group.add_argument('--all', action='store_true', help='æŠ“å–ç›‘è§†åˆ—è¡¨ä¸­çš„æ‰€æœ‰è‚¡ç¥¨')
    fetch_group.add_argument('--tickers', nargs='+', help='æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨')
    
    # ========== ç­–ç•¥ä¿¡å·å‘½ä»¤ ==========
    signal_parser = subparsers.add_parser('signal', help='ç”Ÿæˆäº¤æ˜“ä¿¡å·')
    signal_parser.add_argument('ticker', help='è‚¡ç¥¨ä»£ç ')
    signal_parser.add_argument('--date', help='æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD, é»˜è®¤ä»Šå¤©)')
    signal_parser.add_argument('--entry', help='å…¥åœºç­–ç•¥ (é»˜è®¤: SimpleScorerStrategy)')
    signal_parser.add_argument('--exit', help='å‡ºåœºç­–ç•¥ (é»˜è®¤: ATRExitStrategy)')
    
    # ========== å•è‚¡ç¥¨å›æµ‹å‘½ä»¤ ==========
    backtest_parser = subparsers.add_parser('backtest', help='å•è‚¡ç¥¨å›æµ‹')
    backtest_parser.add_argument('ticker', help='è‚¡ç¥¨ä»£ç ')
    backtest_parser.add_argument('--entry', nargs='+', help='å…¥åœºç­–ç•¥åˆ—è¡¨ (é»˜è®¤: SimpleScorerStrategyï¼Œæ”¯æŒå¤šä¸ª)')
    backtest_parser.add_argument('--exit', nargs='+', help='å‡ºåœºç­–ç•¥åˆ—è¡¨ (é»˜è®¤: ATRExitStrategyï¼Œæ”¯æŒå¤šä¸ª)')
    backtest_parser.add_argument('--all-strategies', action='store_true', help='æµ‹è¯•æ‰€æœ‰ç­–ç•¥ç»„åˆ (9ç§)')
    backtest_parser.add_argument('--years', type=int, help='ä»…å›æµ‹æœ€è¿‘xå¹´ (ä¼˜å…ˆäº--startï¼Œé»˜è®¤: å…¨é‡)')
    backtest_parser.add_argument('--start', help='å¼€å§‹æ—¥æœŸ (é»˜è®¤: 2021-01-01)')
    backtest_parser.add_argument('--end', help='ç»“æŸæ—¥æœŸ (é»˜è®¤: 2026-01-08)')
    backtest_parser.add_argument('--capital', type=int, help='èµ·å§‹èµ„é‡‘ (é»˜è®¤: 5000000)')
    
    # ========== ç»„åˆæŠ•èµ„å›æµ‹å‘½ä»¤ ==========
    portfolio_parser = subparsers.add_parser('portfolio', help='ç»„åˆæŠ•èµ„å›æµ‹')
    portfolio_group = portfolio_parser.add_mutually_exclusive_group(required=True)
    portfolio_group.add_argument('--all', action='store_true', help='ä½¿ç”¨ç›‘è§†åˆ—è¡¨æ‰€æœ‰è‚¡ç¥¨')
    portfolio_group.add_argument('--tickers', nargs='+', help='æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨')
    portfolio_parser.add_argument('--entry', nargs='+', help='å…¥åœºç­–ç•¥åˆ—è¡¨ (é»˜è®¤: SimpleScorerStrategyï¼Œæ”¯æŒå¤šä¸ª)')
    portfolio_parser.add_argument('--exit', nargs='+', help='å‡ºåœºç­–ç•¥åˆ—è¡¨ (é»˜è®¤: ATRExitStrategyï¼Œæ”¯æŒå¤šä¸ª)')
    portfolio_parser.add_argument('--all-strategies', action='store_true', help='æµ‹è¯•æ‰€æœ‰ç­–ç•¥ç»„åˆ (9ç§)')
    portfolio_parser.add_argument('--years', type=int, help='ä»…å›æµ‹æœ€è¿‘xå¹´ (ä¼˜å…ˆäº--startï¼Œé»˜è®¤: å…¨é‡)')
    portfolio_parser.add_argument('--start', help='å¼€å§‹æ—¥æœŸ (é»˜è®¤: 2021-01-01)')
    portfolio_parser.add_argument('--end', help='ç»“æŸæ—¥æœŸ (é»˜è®¤: 2026-01-08)')
    portfolio_parser.add_argument('--capital', type=int, help='èµ·å§‹èµ„é‡‘ (é»˜è®¤: 5000000)')

    # ========== å®‡å®™é€‰è‚¡å‘½ä»¤ï¼ˆæ­£å¼ç‰ˆï¼‰ ==========
    universe_parser = subparsers.add_parser('universe', help='å®‡å®™é€‰è‚¡ï¼ˆä»CSVåŠ è½½ï¼‰')
    universe_parser.add_argument('--csv-file', type=str, help='CSVæ–‡ä»¶è·¯å¾„ (é»˜è®¤: data/jpx_final_list.csv)')
    universe_parser.add_argument('--top-n', type=int, default=50, help='é€‰å‡ºTop Nè‚¡ç¥¨ (é»˜è®¤: 50)')
    universe_parser.add_argument('--limit', type=int, help='ä»…å¤„ç†å‰Næ”¯è‚¡ç¥¨ï¼ˆè°ƒè¯•ç”¨ï¼‰')
    universe_parser.add_argument('--batch-size', type=int, help='æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤100ï¼‰')
    universe_parser.add_argument('--resume', action='store_true', help='ä»checkpointæ–­ç‚¹ç»­ä¼ ')
    universe_parser.add_argument('--checkpoint', type=str, help='æŒ‡å®šcheckpointè·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    universe_parser.add_argument('--no-fetch', action='store_true', help='è·³è¿‡æ•°æ®æŠ“å–ï¼Œç›´æ¥ç”¨ç°æœ‰featuresåšå½’ä¸€åŒ–ï¼ˆå¿«é€Ÿé‡æ–°è¯„åˆ†ï¼‰')
    
    # ========== ç­–ç•¥è¯„ä»·å‘½ä»¤ ==========
    evaluate_parser = subparsers.add_parser('evaluate', help='ç­–ç•¥ç»¼åˆè¯„ä»·ï¼ˆæŒ‰å¹´åº¦/å¸‚åœºç¯å¢ƒï¼‰')
    evaluate_parser.add_argument('--years', nargs='+', type=int, help='å¹´ä»½åˆ—è¡¨ (ä¾‹å¦‚: 2021 2022 2023)')
    evaluate_parser.add_argument('--mode', choices=['annual', 'quarterly', 'monthly', 'custom'], default='annual', 
                                help='è¯„ä¼°æ¨¡å¼: annual=æ•´å¹´, quarterly=å­£åº¦, monthly=æŒ‰æœˆ, custom=è‡ªå®šä¹‰')
    evaluate_parser.add_argument('--months', nargs='+', type=int, help='æœˆä»½åˆ—è¡¨ï¼ˆmonthlyæ¨¡å¼ï¼Œä¾‹å¦‚: 1 2 3ï¼‰')
    evaluate_parser.add_argument('--custom-periods', type=str, help='è‡ªå®šä¹‰æ—¶é—´æ®µï¼ˆJSONæ ¼å¼ï¼‰: [["2021-Q1","2021-01-01","2021-03-31"], ...]')
    evaluate_parser.add_argument('--entry-strategies', nargs='+', help='æŒ‡å®šå…¥åœºç­–ç•¥ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰')
    evaluate_parser.add_argument('--exit-strategies', nargs='+', help='æŒ‡å®šå‡ºåœºç­–ç•¥ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰')
    evaluate_parser.add_argument('--output-dir', default='strategy_evaluation', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: strategy_evaluationï¼‰')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    # æ‰§è¡Œå¯¹åº”å‘½ä»¤
    if args.command == 'fetch':
        cmd_fetch(args)
    elif args.command == 'signal':
        cmd_signal(args)
    elif args.command == 'backtest':
        cmd_backtest(args)
    elif args.command == 'portfolio':
        cmd_portfolio(args)
    elif args.command == 'universe':
        cmd_universe(args)
    elif args.command == 'evaluate':
        cmd_evaluate(args)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
