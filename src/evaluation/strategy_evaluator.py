"""
ç­–ç•¥ç»¼åˆè¯„ä»·å™¨
æŒ‰å¹´åº¦ã€æŒ‰å¸‚åœºç¯å¢ƒè¯„ä¼°ç­–ç•¥ç»„åˆè¡¨ç°

Performance Optimization:
- Parallel backtest execution using ProcessPoolExecutor
- Preloaded data cache to eliminate repeated disk IO
- Configurable worker count for optimal CPU utilization
"""

import json
from concurrent.futures import ProcessPoolExecutor, as_completed
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd

from src.overlays import OverlayManager


@dataclass
class AnnualStrategyResult:
    """å•ä¸ªç­–ç•¥åœ¨å•ä¸ªå¹´åº¦/æ—¶é—´æ®µçš„å›æµ‹ç»“æœ"""

    period: str  # "2021" æˆ– "2021-Q1" æˆ– "2021-01"
    start_date: str  # "2021-01-01"
    end_date: str  # "2021-12-31"
    entry_strategy: str  # "SimpleScorerStrategy"
    exit_strategy: str  # "LayeredExitStrategy"
    return_pct: float  # ç­–ç•¥æ”¶ç›Šç‡
    topix_return_pct: Optional[float]  # TOPIXæ”¶ç›Šç‡ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
    alpha: Optional[float]  # è¶…é¢æ”¶ç›Šç‡ï¼ˆæ— TOPIXæ•°æ®æ—¶ä¸ºNoneï¼‰
    sharpe_ratio: float
    max_drawdown_pct: float
    num_trades: int
    win_rate_pct: float
    avg_gain_pct: float
    avg_loss_pct: float


class MarketRegime:
    """å¸‚åœºç¯å¢ƒåˆ†ç±»"""

    BEAR_MARKET = "ç†Šå¸‚ (TOPIX < 0%)"
    MILD_BULL = "æ¸©å’Œç‰›å¸‚ (TOPIX 0-25%)"
    STRONG_BULL = "å¼ºåŠ²ç‰›å¸‚ (TOPIX 25-50%)"
    SUPER_BULL = "è¶…çº§ç‰›å¸‚ (TOPIX 50-75%)"
    EXTREME_BULL = "æç«¯ç‰›å¸‚ (TOPIX > 75%)"

    @staticmethod
    def classify(topix_return: Optional[float]) -> str:
        """æ ¹æ®TOPIXæ”¶ç›Šç‡åˆ†ç±»å¸‚åœºç¯å¢ƒ"""
        if topix_return is None:
            return "æœªçŸ¥å¸‚åœºç¯å¢ƒ (TOPIXæ•°æ®ç¼ºå¤±)"

        if topix_return < 0:
            return MarketRegime.BEAR_MARKET
        elif topix_return < 25:
            return MarketRegime.MILD_BULL
        elif topix_return < 50:
            return MarketRegime.STRONG_BULL
        elif topix_return < 75:
            return MarketRegime.SUPER_BULL
        else:
            return MarketRegime.EXTREME_BULL


class StrategyEvaluator:
    """
    ç­–ç•¥ç»¼åˆè¯„ä»·å™¨

    åŠŸèƒ½ï¼š
    1. æ‰¹é‡æ‰§è¡Œå¹´åº¦/æ—¶é—´æ®µå›æµ‹
    2. æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç»„åˆ†æ
    3. ç”ŸæˆMarkdownæŠ¥å‘Šå’ŒCSVæ•°æ®

    ç‰¹ç‚¹ï¼š
    - ä¸ä¿®æ”¹ä»»ä½•ç°æœ‰ä»£ç ï¼Œåªè°ƒç”¨portfolio_engine
    - æ”¯æŒçµæ´»çš„æ—¶é—´æ®µæŒ‡å®šï¼ˆæ•´å¹´/å­£åº¦/æœˆåº¦/è‡ªå®šä¹‰ï¼‰
    - æ”¯æŒverboseæ¨¡å¼å’Œç¼“å­˜ä¼˜åŒ–
    """

    def __init__(
        self,
        data_root: str = "data",
        output_dir: str = "strategy_evaluation",
        verbose: bool = False,
        overlay_config: Optional[Dict] = None,
        workers: int = 4,
        use_cache: bool = True,
    ):
        """
        Initialize strategy evaluator.

        Args:
            data_root: Root directory for data files
            output_dir: Output directory for results
            verbose: Enable detailed progress output
            overlay_config: Configuration for overlay manager
            workers: Number of parallel workers (default: 4, set to 1 for serial execution)
            use_cache: Enable data preloading cache for performance (default: True)
        """
        self.data_root = data_root
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.results: List[AnnualStrategyResult] = []
        self.verbose = verbose  # è¯¦ç»†è¾“å‡ºæ¨¡å¼
        self.workers = workers  # Parallel workers
        self.use_cache = use_cache  # Data cache flag

        self.overlay_manager = OverlayManager.from_config(
            overlay_config or {},
            data_root=self.data_root,
        )

        # ç¼“å­˜å±‚ï¼ˆå•æ¬¡è¿è¡Œå†…æœ‰æ•ˆï¼‰
        self._monitor_list_cache = None  # Monitor list ç¼“å­˜
        self._topix_cache: Dict[Tuple[str, str], Optional[float]] = {}  # TOPIX ç¼“å­˜
        self._portfolio_limits_cache: Optional[Tuple[int, float]] = None

    def _get_portfolio_limits(self) -> Tuple[int, float]:
        """
        Load portfolio limits from config.json once.

        Returns:
            (max_positions, max_position_pct)
        """
        if self._portfolio_limits_cache is not None:
            return self._portfolio_limits_cache

        try:
            config_path = Path("config.json")
            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                portfolio_cfg = config.get("portfolio", {})
                max_positions = int(portfolio_cfg.get("max_positions", 7))
                max_position_pct = float(portfolio_cfg.get("max_position_pct", 0.18))
                self._portfolio_limits_cache = (max_positions, max_position_pct)
                return self._portfolio_limits_cache
        except Exception:
            pass

        self._portfolio_limits_cache = (7, 0.18)
        return self._portfolio_limits_cache

    def run_evaluation(
        self,
        periods: List[Tuple[str, str, str]],
        entry_strategies: List[str] = None,
        exit_strategies: List[str] = None,
    ) -> pd.DataFrame:
        """
        æ‰§è¡Œæ‰¹é‡ç­–ç•¥è¯„ä¼°ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬ï¼‰

        Args:
            periods: [(period_label, start_date, end_date), ...]
                    ä¾‹å¦‚: [("2021", "2021-01-01", "2021-12-31"),
                           ("2022-Q1", "2022-01-01", "2022-03-31")]
            entry_strategies: å…¥åœºç­–ç•¥åˆ—è¡¨ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰
            exit_strategies: å‡ºåœºç­–ç•¥åˆ—è¡¨ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰

        Returns:
            DataFrameåŒ…å«æ‰€æœ‰å›æµ‹ç»“æœ
        """
        from src.utils.strategy_loader import ENTRY_STRATEGIES, EXIT_STRATEGIES

        # é»˜è®¤ä½¿ç”¨å…¨éƒ¨ç­–ç•¥
        if entry_strategies is None:
            entry_strategies = list(ENTRY_STRATEGIES.keys())
        if exit_strategies is None:
            exit_strategies = list(EXIT_STRATEGIES.keys())

        total_backtests = len(periods) * len(entry_strategies) * len(exit_strategies)

        # æ€»æ˜¯æ˜¾ç¤ºçš„åŸºæœ¬ä¿¡æ¯
        print(f"\n{'=' * 80}")
        print("ğŸ¯ ç­–ç•¥ç»¼åˆè¯„ä»· (å¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬)")
        print(f"{'=' * 80}")
        print(f"   æ—¶é—´æ®µæ•°é‡: {len(periods)}")
        print(f"   å…¥åœºç­–ç•¥: {len(entry_strategies)}ä¸ª")
        print(f"   å‡ºåœºç­–ç•¥: {len(exit_strategies)}ä¸ª")
        print(f"   æ€»å›æµ‹æ¬¡æ•°: {total_backtests}")
        print(f"   å¹¶è¡ŒWorkers: {self.workers}")
        print(f"   æ•°æ®ç¼“å­˜: {'å¯ç”¨' if self.use_cache else 'ç¦ç”¨'}")
        if self.verbose:
            print("   è¯¦ç»†è¾“å‡º: å¼€å¯")
        else:
            print("   è¾“å‡ºæ¨¡å¼: ç®€æ´ï¼ˆä½¿ç”¨ --verbose æŸ¥çœ‹è¯¦ç»†è¿›åº¦ï¼‰")
        print(f"{'=' * 80}\n")

        # Step 1: Preload data cache (if enabled)
        preloaded_cache = None
        if self.use_cache:
            print("ğŸ“¦ é¢„åŠ è½½æ•°æ®ç¼“å­˜...")
            try:
                from src.backtest.data_cache import BacktestDataCache

                tickers = self._load_monitor_list()
                preloaded_cache = BacktestDataCache(data_root=self.data_root)

                # è®¡ç®—æ‰€éœ€çš„æ—¥æœŸèŒƒå›´
                min_date = min(p[1] for p in periods)  # Earliest start_date
                max_date = max(p[2] for p in periods)  # Latest end_date

                preloaded_cache.preload_tickers(
                    tickers=tickers,
                    start_date=min_date,
                    end_date=max_date,
                    optimize_memory=True,
                )

                memory_dict = preloaded_cache.get_memory_usage()
                total_mb = sum(memory_dict.values())
                print(f"âœ… ç¼“å­˜åŠ è½½å®Œæˆ: {len(tickers)}åªè‚¡ç¥¨, {total_mb:.2f} MB\n")
            except Exception as e:
                print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œæ‰§è¡Œ: {e}\n")
                self.workers = 1
                preloaded_cache = None

        # Step 2: Prepare TOPIX cache
        print("ğŸ“Š é¢„åŠ è½½TOPIXåŸºå‡†æ•°æ®...")
        for period_label, start_date, end_date in periods:
            cache_key = (start_date, end_date)
            if cache_key not in self._topix_cache:
                self._topix_cache[cache_key] = self._get_topix_return(
                    start_date, end_date
                )
        print("âœ… TOPIXæ•°æ®ç¼“å­˜å®Œæˆ\n")

        # Step 3: Create task list
        tasks = []
        for period_label, start_date, end_date in periods:
            topix_return = self._topix_cache.get((start_date, end_date))
            for entry in entry_strategies:
                for exit in exit_strategies:
                    tasks.append(
                        {
                            "period_label": period_label,
                            "start_date": start_date,
                            "end_date": end_date,
                            "entry_strategy": entry,
                            "exit_strategy": exit,
                            "topix_return": topix_return,
                        }
                    )

        # Step 4: Execute backtests (parallel or serial)
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(tasks)} ä¸ªå›æµ‹ä»»åŠ¡...")
        completed = 0

        if self.workers > 1:
            # Parallel execution
            with ProcessPoolExecutor(max_workers=self.workers) as executor:
                future_to_task = {
                    executor.submit(
                        _run_backtest_worker,
                        task["period_label"],
                        task["start_date"],
                        task["end_date"],
                        task["entry_strategy"],
                        task["exit_strategy"],
                        task["topix_return"],
                        self.data_root,
                        self._get_portfolio_limits(),
                        self.overlay_manager.config
                        if hasattr(self.overlay_manager, "config")
                        else {},
                        self.use_cache,
                    ): task
                    for task in tasks
                }

                for future in as_completed(future_to_task):
                    completed += 1
                    progress = (completed / total_backtests) * 100

                    try:
                        result = future.result()
                        if result:
                            self.results.append(result)

                            if self.verbose:
                                alpha_str = (
                                    f"{result.alpha:>6.2f}%"
                                    if result.alpha is not None
                                    else "   N/A "
                                )
                                print(
                                    f"[{completed}/{total_backtests} {progress:.1f}%] "
                                    f"{result.entry_strategy} Ã— {result.exit_strategy} ({result.period}) "
                                    f"âœ“ Return: {result.return_pct:>6.2f}%, Alpha: {alpha_str}"
                                )
                            else:
                                if completed % 25 == 0 or completed == total_backtests:
                                    print(
                                        f"[{completed}/{total_backtests}]",
                                        end=" ",
                                        flush=True,
                                    )
                    except Exception as e:
                        if self.verbose:
                            task = future_to_task[future]
                            print(
                                f"[{completed}/{total_backtests}] "
                                f"{task['entry_strategy']} Ã— {task['exit_strategy']} âœ— Error: {e}"
                            )
        else:
            # Serial execution (backward compatibility)
            for task in tasks:
                completed += 1
                progress = (completed / total_backtests) * 100

                if self.verbose:
                    print(
                        f"[{completed}/{total_backtests} {progress:.1f}%] "
                        f"{task['entry_strategy']} Ã— {task['exit_strategy']}... ",
                        end="",
                        flush=True,
                    )
                else:
                    if completed % 25 == 0 or completed == total_backtests:
                        print(f"[{completed}/{total_backtests}]", end=" ", flush=True)

                try:
                    result = self._run_single_backtest(
                        period_label=task["period_label"],
                        start_date=task["start_date"],
                        end_date=task["end_date"],
                        entry_strategy=task["entry_strategy"],
                        exit_strategy=task["exit_strategy"],
                        topix_return=task["topix_return"],
                        preloaded_cache=preloaded_cache,
                    )

                    self.results.append(result)

                    if self.verbose:
                        alpha_str = (
                            f"{result.alpha:>6.2f}%"
                            if result.alpha is not None
                            else "   N/A "
                        )
                        print(
                            f"âœ“ Return: {result.return_pct:>6.2f}%, Alpha: {alpha_str}"
                        )
                except Exception as e:
                    if self.verbose:
                        print(f"âœ— Error: {str(e)}")
                    continue

        print(f"\n{'=' * 80}")
        print(f"âœ… è¯„ä¼°å®Œæˆï¼å…± {len(self.results)}/{total_backtests} ä¸ªå›æµ‹æˆåŠŸ")
        print(f"{'=' * 80}\n")

        return self._create_results_dataframe()

    def _run_single_backtest(
        self,
        period_label: str,
        start_date: str,
        end_date: str,
        entry_strategy: str,
        exit_strategy: str,
        topix_return: float,
        preloaded_cache=None,
    ) -> AnnualStrategyResult:
        """
        æ‰§è¡Œå•ä¸ªç­–ç•¥çš„å›æµ‹
        è°ƒç”¨ç°æœ‰çš„portfolio_engineï¼ˆä¸ä¿®æ”¹ä»»ä½•ç°æœ‰ä»£ç ï¼‰

        Args:
            preloaded_cache: Optional BacktestDataCache instance for performance
        """
        from src.backtest.portfolio_engine import PortfolioBacktestEngine
        from src.utils.strategy_loader import load_entry_strategy, load_exit_strategy

        # åŠ è½½ç­–ç•¥å®ä¾‹
        entry = load_entry_strategy(entry_strategy)
        exit_inst = load_exit_strategy(exit_strategy)

        # åŠ è½½ç›‘è§†åˆ—è¡¨
        tickers = self._load_monitor_list()

        # è¿è¡Œå›æµ‹ï¼ˆè°ƒç”¨ç°æœ‰åŠŸèƒ½ï¼Œä¸åšä»»ä½•ä¿®æ”¹ï¼‰
        max_positions, max_position_pct = self._get_portfolio_limits()
        engine = PortfolioBacktestEngine(
            data_root=self.data_root,
            starting_capital=5_000_000,
            max_positions=max_positions,
            max_position_pct=max_position_pct,
            overlay_manager=self.overlay_manager,
            preloaded_cache=preloaded_cache,  # Pass cache to engine
        )

        result = engine.backtest_portfolio_strategy(
            tickers=tickers,
            entry_strategy=entry,
            exit_strategy=exit_inst,
            start_date=start_date,
            end_date=end_date,
        )

        # è®¡ç®—alphaï¼šå¦‚æœæ²¡æœ‰TOPIXæ•°æ®ï¼Œåˆ™è®¾ä¸ºNone
        alpha = None
        if topix_return is not None:
            alpha = result.total_return_pct - topix_return

        # æå–ç»“æœå¹¶æ„é€ æ•°æ®å¯¹è±¡
        return AnnualStrategyResult(
            period=period_label,
            start_date=start_date,
            end_date=end_date,
            entry_strategy=entry_strategy,
            exit_strategy=exit_strategy,
            return_pct=result.total_return_pct,
            topix_return_pct=topix_return,
            alpha=alpha,
            sharpe_ratio=result.sharpe_ratio,
            max_drawdown_pct=result.max_drawdown_pct,
            num_trades=result.num_trades,
            win_rate_pct=result.win_rate_pct,
            avg_gain_pct=result.avg_gain_pct,
            avg_loss_pct=result.avg_loss_pct,
        )

    def _get_topix_return(self, start_date: str, end_date: str) -> Optional[float]:
        """
        è®¡ç®—TOPIXåœ¨æŒ‡å®šæ—¶é—´æ®µçš„æ”¶ç›Šç‡
        è°ƒç”¨ç°æœ‰çš„benchmark_managerï¼ˆä¸ä¿®æ”¹ï¼‰
        å¦‚æœæ— æ³•è·å–æ•°æ®ï¼Œè¿”å› None
        """
        from src.data.benchmark_manager import BenchmarkManager

        manager = BenchmarkManager(client=None, data_root=self.data_root)

        try:
            result = manager.calculate_benchmark_return(
                start_date=start_date, end_date=end_date, use_cached=True
            )
            return result  # è¿”å›å®é™…ç»“æœï¼ˆå¯èƒ½æ˜¯Noneï¼‰
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–TOPIXæ•°æ®: {e}")
            return None

    def _load_monitor_list(self) -> List[str]:
        """åŠ è½½ç›‘è§†åˆ—è¡¨ï¼ˆå•æ¬¡è¿è¡Œå†…ç¼“å­˜ï¼Œä» config.json æŒ‡å®šçš„å”¯ä¸€çœŸæºè¯»å–ï¼‰"""
        # è¿”å›ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self._monitor_list_cache is not None:
            return self._monitor_list_cache

        # ä» config.json è¯»å–é…ç½®
        try:
            config_path = Path("config.json")
            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                    monitor_file = Path(config["data"]["monitor_list_file"])
            else:
                # Config ä¸å­˜åœ¨æ—¶å›é€€åˆ°é»˜è®¤è·¯å¾„
                monitor_file = Path(self.data_root) / "monitor_list.json"
        except Exception:
            monitor_file = Path(self.data_root) / "monitor_list.json"

        if not monitor_file.exists():
            raise FileNotFoundError(f"ç›‘è§†åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {monitor_file}")

        # JSON format with tickers array
        if monitor_file.suffix == ".json":
            with open(monitor_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                self._monitor_list_cache = [stock["code"] for stock in data["tickers"]]
                return self._monitor_list_cache

        # TXT format (legacy support)
        tickers = []
        with open(monitor_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    tickers.append(line)
        self._monitor_list_cache = tickers
        return self._monitor_list_cache

    def _create_results_dataframe(self) -> pd.DataFrame:
        """å°†ç»“æœè½¬æ¢ä¸ºDataFrame"""
        if not self.results:
            return pd.DataFrame()

        return pd.DataFrame([asdict(r) for r in self.results])

    def analyze_by_market_regime(self) -> pd.DataFrame:
        """
        æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç»„åˆ†æ

        Returns:
            æŒ‰å¸‚åœºç¯å¢ƒã€ç­–ç•¥ç»„åˆåˆ†ç»„çš„ç»Ÿè®¡ç»“æœ
        """
        df = self._create_results_dataframe()

        if df.empty:
            return df

        # æ·»åŠ å¸‚åœºç¯å¢ƒåˆ†ç±»
        df["market_regime"] = df["topix_return_pct"].apply(MarketRegime.classify)

        # æŒ‰å¸‚åœºç¯å¢ƒå’Œç­–ç•¥ç»„åˆåˆ†ç»„
        grouped = df.groupby(["market_regime", "entry_strategy", "exit_strategy"]).agg(
            {
                "return_pct": ["mean", "std", "min", "max"],
                "alpha": ["mean", "std"],
                "sharpe_ratio": "mean",
                "win_rate_pct": "mean",
                "max_drawdown_pct": "mean",
                "period": "count",  # æ ·æœ¬æ•°é‡
            }
        )

        # é‡å‘½ååˆ—
        grouped.columns = ["_".join(col).strip() for col in grouped.columns.values]
        grouped = grouped.rename(columns={"period_count": "sample_count"})

        # æŒ‰å¸‚åœºç¯å¢ƒå’Œå¹³å‡alphaæ’åº
        grouped = grouped.sort_values(
            ["market_regime", "alpha_mean"], ascending=[True, False]
        )

        return grouped.reset_index()

    def get_top_strategies_by_regime(self, top_n: int = 3) -> Dict[str, pd.DataFrame]:
        """
        æ‰¾å‡ºæ¯ç§å¸‚åœºç¯å¢ƒä¸‹è¡¨ç°æœ€å¥½çš„top Nç­–ç•¥

        Args:
            top_n: æ¯ç§ç¯å¢ƒè¿”å›çš„ç­–ç•¥æ•°é‡

        Returns:
            {market_regime: DataFrame of top strategies}
        """
        df = self._create_results_dataframe()

        if df.empty:
            return {}

        df["market_regime"] = df["topix_return_pct"].apply(MarketRegime.classify)

        results = {}
        for regime in sorted(df["market_regime"].unique()):
            regime_df = df[df["market_regime"] == regime]

            # æŒ‰alphaæ’åºï¼Œå–top N
            top_strategies = regime_df.nlargest(top_n, "alpha")[
                [
                    "period",
                    "entry_strategy",
                    "exit_strategy",
                    "return_pct",
                    "topix_return_pct",
                    "alpha",
                    "sharpe_ratio",
                    "win_rate_pct",
                ]
            ]

            results[regime] = top_strategies

        return results

    def save_results(self, prefix: str = "evaluation"):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶

        ç”Ÿæˆï¼š
        1. {prefix}_raw.csv - åŸå§‹ç»“æœ
        2. {prefix}_by_regime.csv - æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç»„
        3. {prefix}_report.md - MarkdownæŠ¥å‘Š
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 1. åŸå§‹ç»“æœCSV
        df = self._create_results_dataframe()
        raw_file = self.output_dir / f"{prefix}_raw_{timestamp}.csv"
        df.to_csv(raw_file, index=False, encoding="utf-8-sig")
        print(f"âœ… åŸå§‹ç»“æœå·²ä¿å­˜: {raw_file}")

        # 2. æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç»„CSV
        regime_df = self.analyze_by_market_regime()
        regime_file = self.output_dir / f"{prefix}_by_regime_{timestamp}.csv"
        regime_df.to_csv(regime_file, index=False, encoding="utf-8-sig")
        print(f"âœ… å¸‚åœºç¯å¢ƒåˆ†æå·²ä¿å­˜: {regime_file}")

        # 3. MarkdownæŠ¥å‘Š
        report_file = self.output_dir / f"{prefix}_report_{timestamp}.md"
        self._generate_markdown_report(report_file)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        return {
            "raw": str(raw_file),
            "regime": str(regime_file),
            "report": str(report_file),
        }

    def _generate_markdown_report(self, output_file: Path):
        """ç”ŸæˆMarkdownæ ¼å¼çš„è¯„ä»·æŠ¥å‘Š"""
        df = self._create_results_dataframe()

        if df.empty:
            return

        with open(output_file, "w", encoding="utf-8") as f:
            f.write("# ç­–ç•¥ç»¼åˆè¯„ä»·æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # 1. æ€»ä½“æ¦‚è§ˆ
            f.write("## 1. æ€»ä½“æ¦‚è§ˆ\n\n")
            f.write(f"- è¯„ä¼°æ—¶æ®µæ•°: {df['period'].nunique()}\n")
            f.write(
                f"- ç­–ç•¥ç»„åˆæ•°: {len(df.groupby(['entry_strategy', 'exit_strategy']))}\n"
            )
            f.write(f"- æ€»å›æµ‹æ¬¡æ•°: {len(df)}\n")
            f.write(f"- å…¥åœºç­–ç•¥: {', '.join(df['entry_strategy'].unique())}\n")
            f.write(f"- å‡ºåœºç­–ç•¥: {', '.join(df['exit_strategy'].unique())}\n\n")

            # 2. æ—¶æ®µTOPIXè¡¨ç°
            f.write("## 2. æ—¶æ®µTOPIXè¡¨ç°\n\n")
            period_summary = (
                df.groupby("period")
                .agg(
                    {
                        "topix_return_pct": "first",
                        "start_date": "first",
                        "end_date": "first",
                    }
                )
                .reset_index()
            )
            period_summary["market_regime"] = period_summary["topix_return_pct"].apply(
                MarketRegime.classify
            )

            f.write("| æ—¶æ®µ | æ—¥æœŸèŒƒå›´ | TOPIXæ”¶ç›Šç‡ | å¸‚åœºç¯å¢ƒ |\n")
            f.write("|------|---------|------------|----------|\n")
            for _, row in period_summary.iterrows():
                topix_str = (
                    f"{row['topix_return_pct']:.2f}%"
                    if pd.notna(row["topix_return_pct"])
                    else "N/A (æ•°æ®ç¼ºå¤±)"
                )
                f.write(
                    f"| {row['period']} | {row['start_date']} ~ {row['end_date']} | "
                    f"{topix_str} | {row['market_regime']} |\n"
                )
            f.write("\n")

            # 3. æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç±»çš„æœ€ä¼˜ç­–ç•¥
            f.write("## 3. æŒ‰å¸‚åœºç¯å¢ƒåˆ†ç±»çš„æœ€ä¼˜ç­–ç•¥\n\n")
            df["market_regime"] = df["topix_return_pct"].apply(MarketRegime.classify)

            for regime in sorted(df["market_regime"].unique()):
                regime_df = df[df["market_regime"] == regime].copy()

                # æŒ‰ alpha æ’åºï¼ˆæœ‰TOPIXæ•°æ®æ—¶ï¼‰æˆ–æŒ‰ return_pct æ’åºï¼ˆæ— TOPIXæ•°æ®æ—¶ï¼‰
                has_alpha = (
                    regime_df["alpha"].notna().any()
                    and regime_df["topix_return_pct"].notna().any()
                )
                if has_alpha and regime_df["alpha"].sum() != 0:
                    regime_df = regime_df.sort_values("alpha", ascending=False)
                else:
                    regime_df = regime_df.sort_values("return_pct", ascending=False)

                f.write(f"### {regime}\n\n")
                sample_count = len(regime_df)
                periods = regime_df["period"].unique()
                f.write(f"æ ·æœ¬æ•°: {sample_count} (æ—¶æ®µ: {', '.join(periods)})\n\n")

                # è¡¨å¤´ï¼šæ ¹æ®æ˜¯å¦æœ‰TOPIXæ•°æ®åŠ¨æ€è°ƒæ•´
                if (
                    regime_df["topix_return_pct"].notna().any()
                    and regime_df["topix_return_pct"].sum() != 0
                ):
                    f.write(
                        "| æ’å | æ—¶æ®µ | å…¥åœºç­–ç•¥ | å‡ºåœºç­–ç•¥ | æ”¶ç›Šç‡ | è¶…é¢æ”¶ç›Š | å¤æ™®æ¯”ç‡ | èƒœç‡ |\n"
                    )
                    f.write(
                        "|------|------|---------|---------|--------|---------|---------|------|\n"
                    )
                    for idx, (_, row) in enumerate(regime_df.iterrows(), 1):
                        alpha_str = (
                            f"{row['alpha']:.2f}%" if pd.notna(row["alpha"]) else "N/A"
                        )
                        f.write(
                            f"| {idx} | {row['period']} | {row['entry_strategy']} | {row['exit_strategy']} | "
                            f"{row['return_pct']:.2f}% | {alpha_str} | "
                            f"{row['sharpe_ratio']:.2f} | {row['win_rate_pct']:.1f}% |\n"
                        )
                else:
                    f.write(
                        "| æ’å | æ—¶æ®µ | å…¥åœºç­–ç•¥ | å‡ºåœºç­–ç•¥ | æ”¶ç›Šç‡ | å¤æ™®æ¯”ç‡ | èƒœç‡ |\n"
                    )
                    f.write(
                        "|------|------|---------|---------|--------|---------|------|\n"
                    )
                    for idx, (_, row) in enumerate(regime_df.iterrows(), 1):
                        f.write(
                            f"| {idx} | {row['period']} | {row['entry_strategy']} | {row['exit_strategy']} | "
                            f"{row['return_pct']:.2f}% | "
                            f"{row['sharpe_ratio']:.2f} | {row['win_rate_pct']:.1f}% |\n"
                        )
                f.write("\n")

            # 3.5 ç­–ç•¥å•ä½åˆ—è¡¨
            f.write("## 3.5 ç­–ç•¥å•ä½æ€§èƒ½æ±‡æ€»\n\n")
            f.write(
                "æ‰€æœ‰ç­–ç•¥ç»„åˆåœ¨å„æ—¶æ®µã€å„å¸‚åœºç¯å¢ƒä¸‹çš„è¡¨ç°å¯¹æ¯”ï¼ˆæŒ‰æ—¶æ®µå’Œå…¥åœºç­–ç•¥åˆ†ç»„ï¼‰ï¼š\n\n"
            )

            # æŒ‰ç­–ç•¥ç»„åˆåˆ†ç»„ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ—¶æ®µæ•°æ®
            strategies = sorted(
                df.groupby(["entry_strategy", "exit_strategy"]).size().index.tolist()
            )

            f.write("| æ—¶æ®µ | å…¥åœºç­–ç•¥ | å‡ºåœºç­–ç•¥ | æ”¶ç›Šç‡ | è¶…é¢æ”¶ç›Š | å¸‚åœºç¯å¢ƒ |\n")
            f.write("|------|---------|---------|--------|---------|----------|\n")

            for entry_strat, exit_strat in strategies:
                combo_df = df[
                    (df["entry_strategy"] == entry_strat)
                    & (df["exit_strategy"] == exit_strat)
                ].sort_values("period")
                for _, row in combo_df.iterrows():
                    alpha_str = (
                        f"{row['alpha']:.2f}%" if pd.notna(row["alpha"]) else "N/A"
                    )
                    f.write(
                        f"| {row['period']} | {row['entry_strategy']} | {row['exit_strategy']} | "
                        f"{row['return_pct']:.2f}% | {alpha_str} | {row['market_regime']} |\n"
                    )
            f.write("\n")

            # 4. å…¨å¤©å€™ç­–ç•¥æ¨è
            f.write("## 4. å…¨å¤©å€™ç­–ç•¥æ¨è\n\n")

            # ç»Ÿè®¡æ¯ä¸ªç­–ç•¥ç»„åˆåœ¨å„å¸‚åœºç¯å¢ƒä¸­çš„æ’å
            strategy_performance = {}

            for regime in df["market_regime"].unique():
                regime_df = df[df["market_regime"] == regime].copy()

                # æŒ‰ alpha æ’åºï¼ˆæœ‰TOPIXæ•°æ®æ—¶ï¼‰æˆ–æŒ‰ return_pct æ’åºï¼ˆæ— TOPIXæ•°æ®æ—¶ï¼‰
                has_alpha = (
                    regime_df["alpha"].notna().any()
                    and regime_df["topix_return_pct"].notna().any()
                )
                if has_alpha and regime_df["alpha"].sum() != 0:
                    regime_df["rank"] = regime_df["alpha"].rank(ascending=False)
                else:
                    regime_df["rank"] = regime_df["return_pct"].rank(ascending=False)

                for _, row in regime_df.iterrows():
                    key = (row["entry_strategy"], row["exit_strategy"])
                    if key not in strategy_performance:
                        strategy_performance[key] = []
                    strategy_performance[key].append(row["rank"])

            # è®¡ç®—å¹³å‡æ’å
            avg_ranks = {k: sum(v) / len(v) for k, v in strategy_performance.items()}
            sorted_strategies = sorted(avg_ranks.items(), key=lambda x: x[1])

            f.write("åŸºäºè·¨å¸‚åœºç¯å¢ƒè¡¨ç°ï¼ˆå¹³å‡æ’åï¼‰ï¼Œæ¨èç­–ç•¥ï¼š\n\n")

            for i, ((entry, exit), avg_rank) in enumerate(sorted_strategies[:3], 1):
                f.write(f"**{i}. {entry} Ã— {exit}**\n")
                f.write(f"- å¹³å‡æ’å: {avg_rank:.1f}\n")

                # ç»Ÿè®¡åœ¨å„å¸‚åœºç¯å¢ƒçš„è¡¨ç°
                combo_df = df[
                    (df["entry_strategy"] == entry) & (df["exit_strategy"] == exit)
                ]
                f.write(f"- å¹³å‡æ”¶ç›Šç‡: {combo_df['return_pct'].mean():.2f}%\n")

                # æ£€æŸ¥æ˜¯å¦æœ‰TOPIXæ•°æ®
                has_topix_data = (
                    combo_df["topix_return_pct"].notna().any()
                    and combo_df["topix_return_pct"].sum() != 0
                )
                if has_topix_data:
                    f.write(f"- å¹³å‡è¶…é¢æ”¶ç›Š: {combo_df['alpha'].mean():.2f}%\n")

                f.write(f"- å¹³å‡å¤æ™®æ¯”ç‡: {combo_df['sharpe_ratio'].mean():.2f}\n")
                f.write(f"- å¹³å‡èƒœç‡: {combo_df['win_rate_pct'].mean():.1f}%\n\n")


def create_annual_periods(years: List[int]) -> List[Tuple[str, str, str]]:
    """
    åˆ›å»ºå¹´åº¦æ—¶é—´æ®µåˆ—è¡¨

    Args:
        years: [2021, 2022, 2023, ...]

    Returns:
        [("2021", "2021-01-01", "2021-12-31"), ...]
    """
    return [(str(year), f"{year}-01-01", f"{year}-12-31") for year in years]


def create_monthly_periods(
    year: int, months: List[int] = None
) -> List[Tuple[str, str, str]]:
    """
    åˆ›å»ºæœˆåº¦æ—¶é—´æ®µåˆ—è¡¨

    Args:
        year: å¹´ä»½
        months: æœˆä»½åˆ—è¡¨ï¼ˆé»˜è®¤1-12ï¼‰

    Returns:
        [("2021-01", "2021-01-01", "2021-01-31"), ...]
    """
    import calendar

    if months is None:
        months = list(range(1, 13))

    periods = []
    for month in months:
        last_day = calendar.monthrange(year, month)[1]
        periods.append(
            (
                f"{year}-{month:02d}",
                f"{year}-{month:02d}-01",
                f"{year}-{month:02d}-{last_day}",
            )
        )

    return periods


def create_quarterly_periods(years: List[int]) -> List[Tuple[str, str, str]]:
    """
    åˆ›å»ºå­£åº¦æ—¶é—´æ®µåˆ—è¡¨

    Args:
        years: [2021, 2022, ...]

    Returns:
        [("2021-Q1", "2021-01-01", "2021-03-31"), ...]
    """
    periods = []
    quarters = [
        ("Q1", "01-01", "03-31"),
        ("Q2", "04-01", "06-30"),
        ("Q3", "07-01", "09-30"),
        ("Q4", "10-01", "12-31"),
    ]

    for year in years:
        for q_label, start, end in quarters:
            periods.append((f"{year}-{q_label}", f"{year}-{start}", f"{year}-{end}"))

    return periods


# ==================== PARALLEL WORKER FUNCTION ====================


def _run_backtest_worker(
    period_label: str,
    start_date: str,
    end_date: str,
    entry_strategy: str,
    exit_strategy: str,
    topix_return: Optional[float],
    data_root: str,
    portfolio_limits: Tuple[int, float],
    overlay_config: Dict,
    use_cache: bool,
) -> Optional[AnnualStrategyResult]:
    """
    Worker function for parallel backtest execution.

    This function runs in a separate process and must be pickleable.
    Each worker creates its own data cache to avoid multiprocessing serialization issues.

    Args:
        period_label: Period label (e.g., "2021", "2021-Q1")
        start_date: Start date (YYYY-MM-DD)
        end_date: End date (YYYY-MM-DD)
        entry_strategy: Entry strategy name
        exit_strategy: Exit strategy name
        topix_return: TOPIX benchmark return (optional)
        data_root: Data root directory
        portfolio_limits: (max_positions, max_position_pct)
        overlay_config: Overlay manager configuration dict
        use_cache: Whether to use data cache

    Returns:
        AnnualStrategyResult or None if error
    """
    try:
        import json
        from pathlib import Path

        from src.backtest.data_cache import BacktestDataCache
        from src.backtest.portfolio_engine import PortfolioBacktestEngine
        from src.overlays import OverlayManager
        from src.utils.strategy_loader import load_entry_strategy, load_exit_strategy

        # Load strategies
        entry = load_entry_strategy(entry_strategy)
        exit_inst = load_exit_strategy(exit_strategy)

        # Load monitor list (from config.json)
        try:
            config_path = Path("config.json")
            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                    monitor_file = Path(config["data"]["monitor_list_file"])
            else:
                monitor_file = Path(data_root) / "monitor_list.json"
        except Exception:
            monitor_file = Path(data_root) / "monitor_list.json"

        if not monitor_file.exists():
            return None

        with open(monitor_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            tickers = [stock["code"] for stock in data["tickers"]]

        # Create data cache (if enabled)
        preloaded_cache = None
        if use_cache:
            try:
                preloaded_cache = BacktestDataCache(data_root=data_root)
                preloaded_cache.preload_tickers(
                    tickers=tickers,
                    start_date=start_date,
                    end_date=end_date,
                    optimize_memory=True,
                )
            except Exception:
                # Fallback to disk loading if cache fails
                preloaded_cache = None

        # Create overlay manager
        overlay_manager = OverlayManager.from_config(
            overlay_config, data_root=data_root
        )

        # Run backtest
        max_positions, max_position_pct = portfolio_limits
        engine = PortfolioBacktestEngine(
            data_root=data_root,
            starting_capital=5_000_000,
            max_positions=max_positions,
            max_position_pct=max_position_pct,
            overlay_manager=overlay_manager,
            preloaded_cache=preloaded_cache,
        )

        result = engine.backtest_portfolio_strategy(
            tickers=tickers,
            entry_strategy=entry,
            exit_strategy=exit_inst,
            start_date=start_date,
            end_date=end_date,
        )

        # Calculate alpha
        alpha = None
        if topix_return is not None:
            alpha = result.total_return_pct - topix_return

        # Return result
        return AnnualStrategyResult(
            period=period_label,
            start_date=start_date,
            end_date=end_date,
            entry_strategy=entry_strategy,
            exit_strategy=exit_strategy,
            return_pct=result.total_return_pct,
            topix_return_pct=topix_return,
            alpha=alpha,
            sharpe_ratio=result.sharpe_ratio,
            max_drawdown_pct=result.max_drawdown_pct,
            num_trades=result.num_trades,
            win_rate_pct=result.win_rate_pct,
            avg_gain_pct=result.avg_gain_pct,
            avg_loss_pct=result.avg_loss_pct,
        )
    except Exception:
        # Return None on error (logged by main process)
        return None
